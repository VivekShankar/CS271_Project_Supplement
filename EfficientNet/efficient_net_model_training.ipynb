{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "K4E7ctymmNY5"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import timm\n",
    "import torch\n",
    "from albumentations import (\n",
    "    Compose,\n",
    "    Normalize,\n",
    "    ShiftScaleRotate,\n",
    "    RandomBrightnessContrast,\n",
    "    MotionBlur,\n",
    "    CLAHE,\n",
    "    HorizontalFlip\n",
    ")\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4NOaHrfcmGub",
    "outputId": "d7a8c791-f123-4504-cee6-a03cd1a6391c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/vinbigdata-chest-xray-resized-png-256x256/train\n",
      "/home/jupyter/vinbigdata-chest-xray-resized-png-256x256/test\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"/home/jupyter/vinbigdata-chest-xray-resized-png-256x256\"\n",
    "model_path = \"/home/jupyter/vinbigdata-chest-xray-resized-png-256x256/save_models\"\n",
    "class_weights_path = \"/home/jupyter/vinbigdata-chest-xray-resized-png-256x256/class_weights.npy\"\n",
    "\n",
    "train_csv_path = os.path.join(dataset_path, 'vindrcxr_train.csv')\n",
    "test_csv_path = os.path.join(dataset_path, 'vindrcxr_test.csv')\n",
    "train_image_path = os.path.join(dataset_path, 'train')\n",
    "test_image_path = os.path.join(dataset_path, 'test')\n",
    "save_path = os.path.join(model_path, '')\n",
    "\n",
    "print(train_image_path)\n",
    "print(test_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lHkns1-jmLDb"
   },
   "outputs": [],
   "source": [
    "bs = 2\n",
    "lr = 1e-3\n",
    "N_EPOCHS = 10\n",
    "NUM_CLASSES = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LDFZ9sRD8Irl",
    "outputId": "40b196a0-e391-4137-8d47-ae49c3c17bd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28d11d6696649471d0af4e67f7126299.png  save_models  train_meta.csv\n",
      "class_weights.npy\t\t      test.csv\t   vindrcxr_test.csv\n",
      "saliency_map.png\t\t      train.csv    vindrcxr_train.csv\n"
     ]
    }
   ],
   "source": [
    "!ls vinbigdata-chest-xray-resized-png-256x256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CzwoHtq0mlqy"
   },
   "outputs": [],
   "source": [
    "### Code from https://github.com/Scu-sen/VinBigData-Chest-X-ray-Abnormalities-Detection\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, image_path, transform=None):\n",
    "        self.df = df\n",
    "        self.image_path = image_path\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        labels = torch.from_numpy(\n",
    "            self.df.loc[idx,np.arange(0, NUM_CLASSES).astype(str).tolist()].values.astype(float)\n",
    "        ).float()\n",
    "\n",
    "        img = cv2.imread(\n",
    "            self.image_path + '/' + str(self.df.image_id[idx]) + '.png'\n",
    "        )\n",
    "        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        img = torch.from_numpy(img.transpose((2, 0, 1))).float()\n",
    "            \n",
    "        return img, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jvX1xtRGnZ8w"
   },
   "outputs": [],
   "source": [
    "### Modified from https://github.com/Scu-sen/VinBigData-Chest-X-ray-Abnormalities-Detection\n",
    "\n",
    "def train_model(model, data_loader, optimizer, criterion, class_weights):\n",
    "    \"\"\"\n",
    "    Trains the model for 1 epoch\n",
    "    \n",
    "    Parameters:\n",
    "        model (torch.nn.Module): The model to be trained/validated.\n",
    "        data_loader (torch.utils.data.DataLoader): Dataloader object for training/validation.\n",
    "        optimizer (A torch.optim class): The optimizer.\n",
    "        criterion (A function in torch.nn.modules.loss): The loss function. \n",
    "        class_weights (np.array): class_weights[i] represents the weight of class i (inversely prop. to class frequency).\n",
    "        \n",
    "    Return: \n",
    "        avg_loss (float): The average loss.\n",
    "        aucs (List[float]): List of per-class AUCs\n",
    "        overall_auc (float): weighted-average AUC across classes\n",
    "        accs (List[float]): List of per-class accuracies\n",
    "        overall_acc (float): weighted-average accuracy across classes\n",
    "    \"\"\"\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_n = 0\n",
    "    avg_loss = 0.0\n",
    "    preds_list, targets_list = [], []\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    tk = tqdm(data_loader, total=len(data_loader), position=0, leave=True)\n",
    "    # Run model training on each batch from the train data_loader.\n",
    "    for idx, (imgs, labels) in enumerate(tk):\n",
    "        imgs, labels = imgs.cuda(), labels.cuda()\n",
    "        output = model(imgs)\n",
    "        \n",
    "        loss = criterion(output, labels) \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        optimizer.zero_grad() \n",
    "        \n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        running_n += imgs.size(0)\n",
    "        tk.set_postfix(loss=running_loss / running_n)\n",
    "\n",
    "        preds = torch.sigmoid(output).detach().cpu().numpy()\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "      \n",
    "        preds_list.append(preds)\n",
    "        targets_list.append(labels.round().astype(int))\n",
    "\n",
    "    avg_loss = running_loss / running_n\n",
    "\n",
    "    preds_list = np.concatenate(preds_list,axis=0).T\n",
    "    targets_list = np.concatenate(targets_list,axis=0).T\n",
    "    \n",
    "    aucs = np.array(\n",
    "        [roc_auc_score(i,j) if len(set(i))>1 else np.nan for i,j in zip(targets_list, preds_list)]\n",
    "    )\n",
    "    overall_auc = np.nansum(class_weights * aucs)/np.nansum(class_weights)\n",
    "\n",
    "    thresholded_preds_list = np.round(preds_list)\n",
    "    accs = np.array(\n",
    "        [accuracy_score(i,j) if len(set(i))>1 else np.nan for i,j in zip(targets_list, thresholded_preds_list)]\n",
    "    )\n",
    "    overall_acc = np.nansum(class_weights * accs)/np.nansum(class_weights)\n",
    "\n",
    "    return avg_loss, aucs, overall_auc, accs, overall_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bq2eTX7psegu"
   },
   "outputs": [],
   "source": [
    "### Modified from https://github.com/Scu-sen/VinBigData-Chest-X-ray-Abnormalities-Detection\n",
    "\n",
    "def val_model(model, data_loader, criterion, class_weights):\n",
    "    \"\"\"\n",
    "    Tests the model on the validation set\n",
    "    \n",
    "    Parameters:\n",
    "        model (torch.nn.Module): The model to be trained/validated.\n",
    "        data_loader (torch.utils.data.DataLoader): Dataloader object for training/validation.\n",
    "        optimizer (A torch.optim class): The optimizer.\n",
    "        criterion (A torch.nn.modules.loss class): The loss function. \n",
    "        \n",
    "    Return: \n",
    "        avg_loss (float): The average loss.\n",
    "        aucs (List[float]): List of per-class AUCs\n",
    "        overall_auc (float): weighted-average AUC across classes\n",
    "        accs (List[float]): List of per-class accuracies\n",
    "        overall_acc (float): weighted-average accuracy across classes\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_n = 0\n",
    "    avg_loss = 0.0\n",
    "    preds_list, targets_list = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        tk = tqdm(data_loader, total=len(data_loader), position=0, leave=True)\n",
    "        \n",
    "        # Run model inference on each batch from the val data_loader.\n",
    "        for idx, (imgs, labels) in enumerate(tk):  \n",
    "            imgs, labels = imgs.cuda(), labels.cuda()\n",
    "            output = model(imgs)\n",
    "            \n",
    "            loss = criterion(output, labels)\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "            running_n += imgs.size(0)\n",
    "            tk.set_postfix(loss=running_loss / running_n)\n",
    "            \n",
    "            preds = torch.sigmoid(output).detach().cpu().numpy()\n",
    "            labels = labels.detach().cpu().numpy()\n",
    "         \n",
    "            preds_list.append(preds)\n",
    "            targets_list.append(labels.round().astype(int))        \n",
    "        ## Compute Metrics ##\n",
    "        avg_loss = running_loss / running_n\n",
    "\n",
    "        preds_list = np.concatenate(preds_list,axis=0).T\n",
    "        targets_list = np.concatenate(targets_list,axis=0).T\n",
    "        \n",
    "        aucs = np.array(\n",
    "            [roc_auc_score(i,j) if len(set(i))>1 else np.nan for i,j in zip(targets_list, preds_list)]\n",
    "        )\n",
    "        overall_auc = np.nansum(class_weights * aucs)/np.nansum(class_weights)\n",
    "\n",
    "        thresholded_preds_list = np.round(preds_list)\n",
    "        accs = np.array(\n",
    "            [accuracy_score(i,j) if len(set(i))>1 else np.nan for i,j in zip(targets_list, thresholded_preds_list)]\n",
    "        )\n",
    "        overall_acc = np.nansum(class_weights * accs)/np.nansum(class_weights)\n",
    "        \n",
    "    return avg_loss, aucs, overall_auc, accs, overall_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "BKaUGFe1oV5t"
   },
   "outputs": [],
   "source": [
    "### Modified from https://github.com/Scu-sen/VinBigData-Chest-X-ray-Abnormalities-Detection\n",
    "\n",
    "def main():\n",
    "    ## Select fold {0, 1, 2, 3, 4} to use for the validation set.\n",
    "    fold = 0\n",
    "    \n",
    "    # Read the train data and saved class weights.\n",
    "    train = pd.read_csv(train_csv_path)\n",
    "    class_weights = np.load(class_weights_path)\n",
    "    \n",
    "    # Add Training Data Augmentations.\n",
    "    train_transform = Compose([\n",
    "        HorizontalFlip(p=0.5),\n",
    "        ShiftScaleRotate(scale_limit = 0.15, rotate_limit = 10, p = 0.5),\n",
    "        RandomBrightnessContrast(p=0.5),\n",
    "        Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0)\n",
    "    ])\n",
    "    # Validation Data transform.\n",
    "    val_transform = Compose([\n",
    "        Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0)\n",
    "    ])\n",
    "    \n",
    "    # Create Train Dataset and DataLoader.\n",
    "    trainset = Dataset(\n",
    "        train.loc[train['fold'] != fold].reset_index(),\n",
    "        image_path=train_image_path,\n",
    "        transform=train_transform\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        trainset, batch_size=bs, num_workers=1,\n",
    "        shuffle=True \n",
    "    )\n",
    "\n",
    "    # Create Val Dataset and DataLoader.\n",
    "    valset = Dataset(\n",
    "        train.loc[train['fold'] == fold].reset_index(),\n",
    "        image_path=test_image_path,\n",
    "        transform=val_transform\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        valset, batch_size=bs, shuffle=False, num_workers=1\n",
    "    )\n",
    "\n",
    "    # Load EfficientNet B4 model.\n",
    "    model = timm.create_model('tf_efficientnet_b4_ns',pretrained=True,num_classes=15).cuda()\n",
    "    # Setup optimizer (Adam or SGD with momentum\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "    # Add loss function.\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(\n",
    "        pos_weight = torch.FloatTensor(class_weights).cuda()\n",
    "    )\n",
    "    # Add LR scheduler.\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=1, factor=0.1, mode='max')\n",
    "\n",
    "    # Keep track of best model's metrics.\n",
    "    best_weights = deepcopy(model.state_dict())\n",
    "    previous_lr = lr\n",
    "    best_auc = 0\n",
    "    best_aucs = [0]*NUM_CLASSES\n",
    "    best_val_loss = sys.float_info.max\n",
    "    es = 0 # Early stopping parameter.\n",
    "\n",
    "    # Keep track of the train/val loss/accuracy history.\n",
    "    train_loss_history, val_loss_history = [], []\n",
    "    acc_train_history, acc_val_history = [], []\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        # Run training and validation for 1 epoch.\n",
    "        avg_train_loss, aucs_train, auc_train, accs_train, acc_train = train_model(model, train_loader, optimizer, criterion, class_weights)\n",
    "        avg_val_loss, aucs_val, auc_val, accs_val, acc_val = val_model(model, val_loader, criterion, class_weights)\n",
    "\n",
    "        train_loss_history.append(avg_train_loss)\n",
    "        val_loss_history.append(avg_val_loss)\n",
    "        acc_train_history.append(acc_train)\n",
    "        acc_val_history.append(acc_val)\n",
    "\n",
    "        # Report metrics for each epoch.\n",
    "        print('epoch:', epoch)\n",
    "        print(\"Training Metrics\")\n",
    "        print('lr:', previous_lr, 'train_loss:', avg_train_loss, 'weighted avg auc:',auc_train, 'weighted avg acc:', acc_train)\n",
    "        print('aucs:',aucs_train)\n",
    "        print('accs:', accs_train)\n",
    "        print(\"Validation Metrics\")\n",
    "        print('lr:', previous_lr, 'val_loss:',avg_val_loss, 'weighted avg auc:',auc_val, 'weighted avg acc:', acc_val)\n",
    "        print('aucs:',aucs_val)\n",
    "        print('accs:', accs_val)\n",
    "\n",
    "        # Save the best weights if either overall AUC or val_loss improved.\n",
    "        if auc_val > best_auc or avg_val_loss < best_val_loss:\n",
    "            print('saving best weight...')\n",
    "            best_weights = deepcopy(model.state_dict())\n",
    "            for k,v in best_weights.items():\n",
    "                best_weights[k] = v.cpu()\n",
    "\n",
    "        # Save the model for class i if the per-class validation AUC of class i improved.\n",
    "        for i in range(len(best_aucs)):\n",
    "            if aucs_val[i] > best_aucs[i]:\n",
    "                best_aucs[i] = aucs_val[i]\n",
    "                d = {'weight':model.state_dict(), 'auc':aucs_val[i], 'epoch':epoch}\n",
    "                torch.save(d, save_path + f'multilabel_efnb4_v1_adam_cls{i}.pth')\n",
    "\n",
    "        # Update best overall val_loss.\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "\n",
    "        # Update best val AUC\n",
    "        if auc_val > best_auc:\n",
    "            es = 0\n",
    "            best_auc = auc_val\n",
    "        else:\n",
    "            # Early stopping implementation. Stop training if no\n",
    "            # improvement in val AUC in 10 epochs.\n",
    "            es += 1\n",
    "            if es > 10:\n",
    "                break\n",
    "\n",
    "        scheduler.step(auc_val)\n",
    "\n",
    "    # Plot training and validation loss curves.\n",
    "    plt.plot(range(N_EPOCHS), train_loss_history, label='Training Loss')\n",
    "    plt.plot(range(N_EPOCHS), val_loss_history, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.savefig(save_path + f'multilabel_efnb4_v1_loss_history_weighted_adam.png')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-12.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-12:m100"
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "191d5dea2b9247b4881b89e7aca14524": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2c3a077861c1487f90ea2564dc870a29",
       "IPY_MODEL_8828f88a2aa5490bb99cc960f5c64632",
       "IPY_MODEL_56c1afedac2c4c9380520dcca0e9017f"
      ],
      "layout": "IPY_MODEL_20bbeeaf72d146f185e8ed2cec5414ff"
     }
    },
    "20bbeeaf72d146f185e8ed2cec5414ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2bb566ea71634894a5457385b8cfbb16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2c3a077861c1487f90ea2564dc870a29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c90405a7dbdd42c9a87491a3c332b103",
      "placeholder": "​",
      "style": "IPY_MODEL_d195ff17297744a7bbff2d62809aad8c",
      "value": "  0%"
     }
    },
    "45affab672f94ff8875d1592d807bc7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "56c1afedac2c4c9380520dcca0e9017f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_86bd25e2a4f940f4a7727e60d718de6c",
      "placeholder": "​",
      "style": "IPY_MODEL_45affab672f94ff8875d1592d807bc7c",
      "value": " 29/6002 [00:23&lt;3:30:31,  2.11s/it, loss=0.405]"
     }
    },
    "590cb93ef7d04962aa899305361e891c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86bd25e2a4f940f4a7727e60d718de6c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8828f88a2aa5490bb99cc960f5c64632": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_590cb93ef7d04962aa899305361e891c",
      "max": 6002,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2bb566ea71634894a5457385b8cfbb16",
      "value": 29
     }
    },
    "c90405a7dbdd42c9a87491a3c332b103": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d195ff17297744a7bbff2d62809aad8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
